{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from urllib import urlretrieve\n",
    "import cPickle as pickle\n",
    "import os\n",
    "import gzip\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "\n",
    "import lasagne\n",
    "from lasagne import layers\n",
    "from lasagne.updates import adam\n",
    "\n",
    "from nolearn.lasagne import NeuralNet\n",
    "from nolearn.lasagne import visualize\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def contracting_block(layer):\n",
    "    #ugotovi num_filters, padding\n",
    "    layer = layers.Conv3DLayer(layer, num_filters=1, filter_size=(3, 3, 3), stride=2)\n",
    "    tmp_layer = layer\n",
    "    #ugotovi primeren batch norm layer\n",
    "    layer = layers.BatchNormLayer(layer)\n",
    "    #ugotovi primeren prelu layer\n",
    "    layer = layers.prelu(layer)\n",
    "    #ugotovi num_filters, padding\n",
    "    layer = layers.Conv3DLayer(layer, num_filters=1, filter_size=(3, 3, 3), stride=1)\n",
    "    #ugotovi pravilen merge function\n",
    "    layer = layers.ElemwiseMergeLayer([layer, tmp_layer], add)\n",
    "    layer = layers.BatchNormLayer(layer)\n",
    "    layer = layers.prelu(layer)\n",
    "    return layer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def start(input):\n",
    "    layer = layers.Conv3DLayer(input, num_filters=1, filter_size=(3, 3, 3), stride=1)\n",
    "    layer = layers.BatchNormLayer(layer)\n",
    "    layer = layers.prelu(layer)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def expanding_block(layer):\n",
    "    # dodaj feature merging block\n",
    "    layer = layers.Conv3DLayer(layer, num_filters=1, filter_size=(1, 1, 1), stride=1)\n",
    "    layer = layers.BatchNormLayer(layer)\n",
    "    layer = layers.prelu(layer)\n",
    "    # kako deluje deconvolutional layer\n",
    "    layer = layers.Conv3DLayer(input, num_filters=1, filter_size=(3, 3, 3), stride=0.5)\n",
    "    layer = layers.BatchNormLayer(layer)\n",
    "    layer = layers.prelu(layer)\n",
    "    layer = layers.Conv3DLayer(layer, num_filters=1, filter_size=(1, 1, 1), stride=1)\n",
    "    layer = layers.BatchNormLayer(layer)\n",
    "    layer = layers.prelu(layer)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#input_var = T.tensor4('X')\n",
    "#target_var = T.tensor4('y')\n",
    "\n",
    "#input = lasagne.layers.InputLayer((None, 3, 32, 32), input_var)\n",
    "layer = start(input)\n",
    "layer = contracting_block(layer)\n",
    "layer = expanding_block(layer)\n",
    "\n",
    "prediction = lasagne.layers.get_output(layer)\n",
    "#uporabiti pravi loss metric\n",
    "loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "#loss = loss.mean() + 1e-4 * lasagne.regularization.regularize_network_params(\n",
    "#        network, lasagne.regularization.l2)\n",
    "\n",
    "# create parameter update expressions\n",
    "params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "updates = lasagne.updates.adam(loss, params, learning_rate=0.01,\n",
    "                                            momentum=0.9)\n",
    "\n",
    "# compile training function that updates parameters and returns training loss\n",
    "train_fn = theano.function([input_var, target_var], loss, updates=updates)\n",
    "\n",
    "# train network (assuming you've got some training data in numpy arrays)\n",
    "for epoch in range(100):\n",
    "    loss = 0\n",
    "    for input_batch, target_batch in training_data:\n",
    "        loss += train_fn(input_batch, target_batch)\n",
    "    print(\"Epoch %d: Loss %g\" % (epoch + 1, loss / len(training_data)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
