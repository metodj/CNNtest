{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "#from urllib import urlretrieve\n",
    "#import cPickle as pickle\n",
    "import os\n",
    "#import gzip\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "\n",
    "import lasagne\n",
    "from lasagne import layers\n",
    "from lasagne.updates import adam\n",
    "\n",
    "#from nolearn.lasagne import NeuralNet\n",
    "#from nolearn.lasagne import visualize\n",
    "\n",
    "#from ConvTranspose import Conv3DLayerTransposed\n",
    "\n",
    "#from sklearn.metrics import classification_report\n",
    "#from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano.tensor as T\n",
    "\n",
    "from lasagne import init\n",
    "from lasagne import nonlinearities\n",
    "from lasagne.utils import as_tuple\n",
    "from lasagne.theano_extensions import conv\n",
    "\n",
    "from lasagne.layers.base import Layer\n",
    "\n",
    "def conv_output_length(input_length, filter_size, stride, pad=0):\n",
    "    if input_length is None:\n",
    "        return None\n",
    "    if pad == 'valid':\n",
    "        output_length = input_length - filter_size + 1\n",
    "    elif pad == 'full':\n",
    "        output_length = input_length + filter_size - 1\n",
    "    elif pad == 'same':\n",
    "        output_length = input_length\n",
    "    elif isinstance(pad, int):\n",
    "        output_length = input_length + 2 * pad - filter_size + 1\n",
    "    else:\n",
    "        raise ValueError('Invalid pad: {0}'.format(pad))\n",
    "\n",
    "    # This is the integer arithmetic equivalent to\n",
    "    # np.ceil(output_length / stride)\n",
    "    output_length = (output_length + stride - 1) // stride\n",
    "\n",
    "    return output_length\n",
    "\n",
    "\n",
    "def conv_input_length(output_length, filter_size, stride, pad=0):\n",
    "      \n",
    "    if output_length is None:\n",
    "        return None\n",
    "    if pad == 'valid':\n",
    "        pad = 0\n",
    "    elif pad == 'full':\n",
    "        pad = filter_size - 1\n",
    "    elif pad == 'same':\n",
    "        pad = filter_size // 2\n",
    "    if not isinstance(pad, int):\n",
    "        raise ValueError('Invalid pad: {0}'.format(pad))\n",
    "    return (output_length - 1) * stride - 2 * pad + filter_size\n",
    "\n",
    "\n",
    "class BaseConvLayer(Layer):\n",
    "    def __init__(self, incoming, num_filters, filter_size, stride=1, pad=0,\n",
    "                 untie_biases=False,\n",
    "                 W=init.GlorotUniform(), b=init.Constant(0.),\n",
    "                 nonlinearity=nonlinearities.rectify, flip_filters=True,\n",
    "                 n=None, **kwargs):\n",
    "        super(BaseConvLayer, self).__init__(incoming, **kwargs)\n",
    "        if nonlinearity is None:\n",
    "            self.nonlinearity = nonlinearities.identity\n",
    "        else:\n",
    "            self.nonlinearity = nonlinearity\n",
    "\n",
    "        if n is None:\n",
    "            n = len(self.input_shape) - 2\n",
    "        elif n != len(self.input_shape) - 2:\n",
    "            raise ValueError(\"Tried to create a %dD convolution layer with \"\n",
    "                             \"input shape %r. Expected %d input dimensions \"\n",
    "                             \"(batchsize, channels, %d spatial dimensions).\" %\n",
    "                             (n, self.input_shape, n+2, n))\n",
    "        self.n = n\n",
    "        self.num_filters = num_filters\n",
    "        self.filter_size = as_tuple(filter_size, n, int)\n",
    "        self.flip_filters = flip_filters\n",
    "        self.stride = as_tuple(stride, n, int)\n",
    "        self.untie_biases = untie_biases\n",
    "\n",
    "        if pad == 'same':\n",
    "            if any(s % 2 == 0 for s in self.filter_size):\n",
    "                raise NotImplementedError(\n",
    "                    '`same` padding requires odd filter size.')\n",
    "        if pad == 'valid':\n",
    "            self.pad = as_tuple(0, n)\n",
    "        elif pad in ('full', 'same'):\n",
    "            self.pad = pad\n",
    "        else:\n",
    "            self.pad = as_tuple(pad, n, int)\n",
    "\n",
    "        self.W = self.add_param(W, self.get_W_shape(), name=\"W\")\n",
    "        if b is None:\n",
    "            self.b = None\n",
    "        else:\n",
    "            if self.untie_biases:\n",
    "                biases_shape = (num_filters,) + self.output_shape[2:]\n",
    "            else:\n",
    "                biases_shape = (num_filters,)\n",
    "            self.b = self.add_param(b, biases_shape, name=\"b\",\n",
    "                                    regularizable=False)\n",
    "\n",
    "    def get_W_shape(self):\n",
    "        \"\"\"Get the shape of the weight matrix `W`.\n",
    "        Returns\n",
    "        -------\n",
    "        tuple of int\n",
    "            The shape of the weight matrix.\n",
    "        \"\"\"\n",
    "        num_input_channels = self.input_shape[1]\n",
    "        return (self.num_filters, num_input_channels) + self.filter_size\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        pad = self.pad if isinstance(self.pad, tuple) else (self.pad,) * self.n\n",
    "        batchsize = input_shape[0]\n",
    "        return ((batchsize, self.num_filters) +\n",
    "                tuple(conv_output_length(input, filter, stride, p)\n",
    "                      for input, filter, stride, p\n",
    "                      in zip(input_shape[2:], self.filter_size,\n",
    "                             self.stride, pad)))\n",
    "\n",
    "    def get_output_for(self, input, **kwargs):\n",
    "        conved = self.convolve(input, **kwargs)\n",
    "\n",
    "        if self.b is None:\n",
    "            activation = conved\n",
    "        elif self.untie_biases:\n",
    "            activation = conved + T.shape_padleft(self.b, 1)\n",
    "        else:\n",
    "            activation = conved + self.b.dimshuffle(('x', 0) + ('x',) * self.n)\n",
    "\n",
    "        return self.nonlinearity(activation)\n",
    "\n",
    "    def convolve(self, input, **kwargs):\n",
    "        \"\"\"\n",
    "        Symbolically convolves `input` with ``self.W``, producing an output of\n",
    "        shape ``self.output_shape``. To be implemented by subclasses.\n",
    "        Parameters\n",
    "        ----------\n",
    "        input : Theano tensor\n",
    "            The input minibatch to convolve\n",
    "        **kwargs\n",
    "            Any additional keyword arguments from :meth:`get_output_for`\n",
    "        Returns\n",
    "        -------\n",
    "        Theano tensor\n",
    "            `input` convolved according to the configuration of this layer,\n",
    "            without any bias or nonlinearity applied.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"BaseConvLayer does not implement the \"\n",
    "                                  \"convolve() method. You will want to \"\n",
    "                                  \"use a subclass such as Conv2DLayer.\")\n",
    "\n",
    "class Conv3DLayerTransposed(BaseConvLayer):\n",
    "\n",
    "    #pad spremenim v crop, flip_filters nastavim na True, spremenim super()\n",
    "    def __init__(self, incoming, num_filters, filter_size, stride=(1, 1, 1),\n",
    "                 crop=0, untie_biases=False,\n",
    "                 W=init.GlorotUniform(), b=init.Constant(0.),\n",
    "                 nonlinearity=nonlinearities.rectify, flip_filters=False,\n",
    "                 convolution=T.nnet.ConvTransp3D, output_size=None, **kwargs):\n",
    "        super(Conv3DLayerTransposed, self).__init__(incoming, num_filters, filter_size,\n",
    "                                          stride, crop, untie_biases, W, b,\n",
    "                                          nonlinearity, flip_filters, n=3,\n",
    "                                          **kwargs)\n",
    "        self.crop = self.pad\n",
    "        del self.pad\n",
    "        self.convolution = convolution\n",
    "        self.output_size = output_size\n",
    "        \n",
    "    def get_W_shape(self):\n",
    "        num_input_channels = self.input_shape[1]\n",
    "        # first two sizes are swapped compared to a forward convolution\n",
    "        return (num_input_channels, self.num_filters) + self.filter_size\n",
    "    \n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        #if self.output_size is not None:\n",
    "         #   size = self.output_size\n",
    "        #     if isinstance(self.output_size, T.Variable):\n",
    "        #        size = (None, None)\n",
    "        #    return input_shape[0], self.num_filters, size[0], size[1]\n",
    "\n",
    "        # If self.output_size is not specified, return the smallest shape\n",
    "        # when called from the constructor, self.crop is still called self.pad:\n",
    "        crop = getattr(self, 'crop', getattr(self, 'pad', None))\n",
    "        crop = crop if isinstance(crop, tuple) else (crop,) * self.n\n",
    "        batchsize = input_shape[0]\n",
    "        return ((batchsize, self.num_filters) +\n",
    "                tuple(conv_input_length(input, filter, stride, p)\n",
    "                      for input, filter, stride, p\n",
    "                      in zip(input_shape[2:], self.filter_size,\n",
    "                             self.stride, crop)))\n",
    "\n",
    "    #pad v crop, filter_flip nastavim na not \n",
    "    #def convolve(self, input, **kwargs):\n",
    "    #    border_mode = 'half' if self.crop == 'same' else self.crop\n",
    "    #    conved = self.convolution(input, self.W, self.input_shape, self.get_W_shape(),\n",
    "    #                              subsample=self.stride,\n",
    "    #                              border_mode=border_mode,\n",
    "    #                              filter_flip=not self.flip_filters)\n",
    "    #    return conved\n",
    "    \n",
    "    def convolve(self, input, **kwargs):\n",
    "        border_mode = 'half' if self.crop == 'same' else self.crop\n",
    "        op = T.nnet.abstract_conv.AbstractConv3d_gradInputs(\n",
    "            imshp=self.output_shape,\n",
    "            kshp=self.get_W_shape(),\n",
    "            subsample=self.stride, border_mode=border_mode,\n",
    "            filter_flip=not self.flip_filters)\n",
    "        output_size = self.output_shape[2:]\n",
    "        if isinstance(self.output_size, T.Variable):\n",
    "            output_size = self.output_size\n",
    "        elif any(s is None for s in output_size):\n",
    "            output_size = self.get_output_shape_for(input.shape)[2:]\n",
    "        conved = op(self.W, input, output_size)\n",
    "        return conved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def contracting_block(layer):\n",
    "    #ugotovi num_filters, padding\n",
    "    layer = layers.Conv3DLayer(layer, num_filters=1, filter_size=(2, 2, 2), stride=2, pad=0, W=lasagne.init.Normal())\n",
    "    #print(theano.tensor.shape(lasagne.layers.get_output(layer)))\n",
    "    tmp_layer = layer\n",
    "    #ugotovi primeren batch norm layer\n",
    "    layer = layers.BatchNormLayer(layer)\n",
    "    #ugotovi primeren prelu layer\n",
    "    layer = layers.prelu(layer)\n",
    "    #ugotovi num_filters, padding\n",
    "    layer = layers.Conv3DLayer(layer, num_filters=1, filter_size=(3, 3, 3), stride=1, pad=1, W=lasagne.init.Normal())\n",
    "    #print(theano.tensor.shape(lasagne.layers.get_output(layer)))\n",
    "    layer = layers.ElemwiseSumLayer([layer, tmp_layer])\n",
    "    layer = layers.batch_norm(layer)\n",
    "    layer = layers.prelu(layer)\n",
    "    return layer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def start(input):\n",
    "    layer = layers.Conv3DLayer(input, num_filters=1, filter_size=(3, 3, 3), stride=1, pad=1, W=lasagne.init.Normal())\n",
    "    #print(theano.tensor.shape(lasagne.layers.get_output(layer)))\n",
    "    #print(theano.tensor.shape(lasagne.layers.get_output(layer)))\n",
    "    layer = layers.BatchNormLayer(layer)\n",
    "    layer = layers.prelu(layer)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def expanding_block(layer, tmp):\n",
    "    # dodaj feature merging block\n",
    "    layer = layers.Conv3DLayer(layer, num_filters=1, filter_size=(1, 1, 1), stride=1, pad=0, W=lasagne.init.Normal())\n",
    "    layer = layers.BatchNormLayer(layer)\n",
    "    layer = layers.prelu(layer)\n",
    "    # kako deluje deconvolutional layer --> DEKONVOLUCIJA\n",
    "    #layer = layers.Conv3DLayer(layer, num_filters=1, filter_size=(1, 1, 1), stride=1, pad=0.5)\n",
    "    layer = Conv3DLayerTransposed(layer, num_filters=1, filter_size=(2, 2, 2), stride=2, crop=0, W=lasagne.init.Normal())\n",
    "    layer = layers.BatchNormLayer(layer)\n",
    "    layer = layers.prelu(layer)\n",
    "    layer = layers.ConcatLayer([layer, tmp])\n",
    "    layer = layers.Conv3DLayer(layer, num_filters=1, filter_size=(3, 3, 3), stride=1, pad=1, W=lasagne.init.Normal())\n",
    "    layer = layers.BatchNormLayer(layer)\n",
    "    layer = layers.prelu(layer)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binary_jaccard_index(predictions,targets):\n",
    "    intersection = theano.tensor.minimum(predictions, targets)\n",
    "    union = theano.tensor.maximum(predictions, targets)\n",
    "    axes = tuple(range(1,5))\n",
    "    return intersection.sum(axis=axes) / union.sum(axis=axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prikaze eno 3d sliko\n",
    "def display_numpy(picture):\n",
    "    fig = plt.figure()\n",
    "    for num,slice in enumerate(picture):\n",
    "        y = fig.add_subplot(4,6,num+1)\n",
    "        y.imshow(slice, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10L, 1L, 24L, 160L, 160L)\n",
      "(10L, 1L, 24L, 160L, 160L)\n"
     ]
    }
   ],
   "source": [
    "#load the data\n",
    "\n",
    "data = np.load('data-160-160-24.npy')\n",
    "seg_data = np.load('segdata-160-160-24.npy')\n",
    "\n",
    "data = np.expand_dims(data, axis=1)\n",
    "seg_data = np.expand_dims(seg_data, axis=1)\n",
    "\n",
    "print(data.shape)\n",
    "print(seg_data.shape)\n",
    "\n",
    "train_data = data[:-2]\n",
    "validation_data = data[-2:]\n",
    "train_seg = seg_data[:-2]\n",
    "validation_seg = seg_data[-2:]\n",
    "\n",
    "#display_numpy(train_data[1][0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_var = theano.tensor.tensor5()\n",
    "target_var = theano.tensor.tensor5()\n",
    "\n",
    "\n",
    "layer = lasagne.layers.InputLayer((None, 1, 24, 160, 160), input_var)\n",
    "layer = start(layer)\n",
    "tmp1 = layer\n",
    "layer = contracting_block(layer)\n",
    "tmp2 = layer\n",
    "layer = contracting_block(layer)\n",
    "tmp3 = layer\n",
    "layer = contracting_block(layer)\n",
    "layer = expanding_block(layer, tmp3)\n",
    "#tmp4 = layers.Conv3DLayer(layer, num_filters=1, filter_size=(1, 1, 1), stride=1, pad=0)\n",
    "layer = expanding_block(layer, tmp2)\n",
    "#tmp5 = layers.Conv3DLayer(layer, num_filters=1, filter_size=(1, 1, 1), stride=1, pad=0)\n",
    "layer = expanding_block(layer, tmp1)\n",
    "#tmp6 = layers.Conv3DLayer(layer, num_filters=1, filter_size=(1, 1, 1), stride=1, pad=0)\n",
    "\n",
    "prediction = lasagne.layers.get_output(layer)\n",
    "#uporabiti pravi loss metric\n",
    "loss = lasagne.objectives.squared_error(prediction, target_var)\n",
    "loss = loss.mean() + 1e-4 * lasagne.regularization.regularize_network_params(layer, lasagne.regularization.l2)\n",
    "\n",
    "#print(loss.eval())\n",
    "\n",
    "# create parameter update expressions\n",
    "params = lasagne.layers.get_all_params(layer, trainable=True)\n",
    "updates = lasagne.updates.adam(loss, params, learning_rate=0.001)\n",
    "\n",
    "# compile training function that updates parameters and returns training loss\n",
    "train_fn = theano.function([input_var, target_var], [loss, prediction], updates=updates)\n",
    "\n",
    "# train network (assuming you've got some training data in numpy arrays)\n",
    "for epoch in range(10):\n",
    "    #visualize.plot_conv_weights(layer)\n",
    "    #print(lasagne.utils.floatX(prediction).shape)\n",
    "    loss = train_fn(train_data, train_seg)\n",
    "    #print(loss[1].shape)\n",
    "    #print(type(loss[1]))\n",
    "    #display_numpy(loss[1][0][0]) #tole odkomentiraj za slikce :)\n",
    "    #theano.printing.pprint(prediction[2][2]) \n",
    "    print(\"Epoch %d: Loss %g\" % (epoch + 1, loss[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "x = 2\n",
    "print(eval('x'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
