{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "#from urllib import urlretrieve\n",
    "#import cPickle as pickle\n",
    "import os\n",
    "#import gzip\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "\n",
    "import lasagne\n",
    "from lasagne import layers\n",
    "from lasagne.updates import adam\n",
    "\n",
    "#from nolearn.lasagne import NeuralNet\n",
    "from nolearn.lasagne import visualize\n",
    "\n",
    "#from ConvTranspose import Conv3DLayerTransposed\n",
    "\n",
    "#from sklearn.metrics import classification_report\n",
    "#from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano.tensor as T\n",
    "\n",
    "from lasagne import init\n",
    "from lasagne import nonlinearities\n",
    "from lasagne.utils import as_tuple\n",
    "from lasagne.theano_extensions import conv\n",
    "\n",
    "from lasagne.layers.base import Layer\n",
    "\n",
    "def conv_output_length(input_length, filter_size, stride, pad=0):\n",
    "    if input_length is None:\n",
    "        return None\n",
    "    if pad == 'valid':\n",
    "        output_length = input_length - filter_size + 1\n",
    "    elif pad == 'full':\n",
    "        output_length = input_length + filter_size - 1\n",
    "    elif pad == 'same':\n",
    "        output_length = input_length\n",
    "    elif isinstance(pad, int):\n",
    "        output_length = input_length + 2 * pad - filter_size + 1\n",
    "    else:\n",
    "        raise ValueError('Invalid pad: {0}'.format(pad))\n",
    "\n",
    "    # This is the integer arithmetic equivalent to\n",
    "    # np.ceil(output_length / stride)\n",
    "    output_length = (output_length + stride - 1) // stride\n",
    "\n",
    "    return output_length\n",
    "\n",
    "\n",
    "def conv_input_length(output_length, filter_size, stride, pad=0):\n",
    "      \n",
    "    if output_length is None:\n",
    "        return None\n",
    "    if pad == 'valid':\n",
    "        pad = 0\n",
    "    elif pad == 'full':\n",
    "        pad = filter_size - 1\n",
    "    elif pad == 'same':\n",
    "        pad = filter_size // 2\n",
    "    if not isinstance(pad, int):\n",
    "        raise ValueError('Invalid pad: {0}'.format(pad))\n",
    "    return (output_length - 1) * stride - 2 * pad + filter_size\n",
    "\n",
    "\n",
    "class BaseConvLayer(Layer):\n",
    "    def __init__(self, incoming, num_filters, filter_size, stride=1, pad=0,\n",
    "                 untie_biases=False,\n",
    "                 W=init.GlorotUniform(), b=init.Constant(0.),\n",
    "                 nonlinearity=nonlinearities.rectify, flip_filters=True,\n",
    "                 n=None, **kwargs):\n",
    "        super(BaseConvLayer, self).__init__(incoming, **kwargs)\n",
    "        if nonlinearity is None:\n",
    "            self.nonlinearity = nonlinearities.identity\n",
    "        else:\n",
    "            self.nonlinearity = nonlinearity\n",
    "\n",
    "        if n is None:\n",
    "            n = len(self.input_shape) - 2\n",
    "        elif n != len(self.input_shape) - 2:\n",
    "            raise ValueError(\"Tried to create a %dD convolution layer with \"\n",
    "                             \"input shape %r. Expected %d input dimensions \"\n",
    "                             \"(batchsize, channels, %d spatial dimensions).\" %\n",
    "                             (n, self.input_shape, n+2, n))\n",
    "        self.n = n\n",
    "        self.num_filters = num_filters\n",
    "        self.filter_size = as_tuple(filter_size, n, int)\n",
    "        self.flip_filters = flip_filters\n",
    "        self.stride = as_tuple(stride, n, int)\n",
    "        self.untie_biases = untie_biases\n",
    "\n",
    "        if pad == 'same':\n",
    "            if any(s % 2 == 0 for s in self.filter_size):\n",
    "                raise NotImplementedError(\n",
    "                    '`same` padding requires odd filter size.')\n",
    "        if pad == 'valid':\n",
    "            self.pad = as_tuple(0, n)\n",
    "        elif pad in ('full', 'same'):\n",
    "            self.pad = pad\n",
    "        else:\n",
    "            self.pad = as_tuple(pad, n, int)\n",
    "\n",
    "        self.W = self.add_param(W, self.get_W_shape(), name=\"W\")\n",
    "        if b is None:\n",
    "            self.b = None\n",
    "        else:\n",
    "            if self.untie_biases:\n",
    "                biases_shape = (num_filters,) + self.output_shape[2:]\n",
    "            else:\n",
    "                biases_shape = (num_filters,)\n",
    "            self.b = self.add_param(b, biases_shape, name=\"b\",\n",
    "                                    regularizable=False)\n",
    "\n",
    "    def get_W_shape(self):\n",
    "        \"\"\"Get the shape of the weight matrix `W`.\n",
    "        Returns\n",
    "        -------\n",
    "        tuple of int\n",
    "            The shape of the weight matrix.\n",
    "        \"\"\"\n",
    "        num_input_channels = self.input_shape[1]\n",
    "        return (self.num_filters, num_input_channels) + self.filter_size\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        pad = self.pad if isinstance(self.pad, tuple) else (self.pad,) * self.n\n",
    "        batchsize = input_shape[0]\n",
    "        return ((batchsize, self.num_filters) +\n",
    "                tuple(conv_output_length(input, filter, stride, p)\n",
    "                      for input, filter, stride, p\n",
    "                      in zip(input_shape[2:], self.filter_size,\n",
    "                             self.stride, pad)))\n",
    "\n",
    "    def get_output_for(self, input, **kwargs):\n",
    "        conved = self.convolve(input, **kwargs)\n",
    "\n",
    "        if self.b is None:\n",
    "            activation = conved\n",
    "        elif self.untie_biases:\n",
    "            activation = conved + T.shape_padleft(self.b, 1)\n",
    "        else:\n",
    "            activation = conved + self.b.dimshuffle(('x', 0) + ('x',) * self.n)\n",
    "\n",
    "        return self.nonlinearity(activation)\n",
    "\n",
    "    def convolve(self, input, **kwargs):\n",
    "        \"\"\"\n",
    "        Symbolically convolves `input` with ``self.W``, producing an output of\n",
    "        shape ``self.output_shape``. To be implemented by subclasses.\n",
    "        Parameters\n",
    "        ----------\n",
    "        input : Theano tensor\n",
    "            The input minibatch to convolve\n",
    "        **kwargs\n",
    "            Any additional keyword arguments from :meth:`get_output_for`\n",
    "        Returns\n",
    "        -------\n",
    "        Theano tensor\n",
    "            `input` convolved according to the configuration of this layer,\n",
    "            without any bias or nonlinearity applied.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"BaseConvLayer does not implement the \"\n",
    "                                  \"convolve() method. You will want to \"\n",
    "                                  \"use a subclass such as Conv2DLayer.\")\n",
    "\n",
    "class Conv3DLayerTransposed(BaseConvLayer):\n",
    "\n",
    "    #pad spremenim v crop, flip_filters nastavim na True, spremenim super()\n",
    "    def __init__(self, incoming, num_filters, filter_size, stride=(1, 1, 1),\n",
    "                 crop=0, untie_biases=False,\n",
    "                 W=init.GlorotUniform(), b=init.Constant(0.),\n",
    "                 nonlinearity=nonlinearities.rectify, flip_filters=False,\n",
    "                 convolution=T.nnet.ConvTransp3D, output_size=None, **kwargs):\n",
    "        super(Conv3DLayerTransposed, self).__init__(incoming, num_filters, filter_size,\n",
    "                                          stride, crop, untie_biases, W, b,\n",
    "                                          nonlinearity, flip_filters, n=3,\n",
    "                                          **kwargs)\n",
    "        self.crop = self.pad\n",
    "        del self.pad\n",
    "        self.convolution = convolution\n",
    "        self.output_size = output_size\n",
    "        \n",
    "    def get_W_shape(self):\n",
    "        num_input_channels = self.input_shape[1]\n",
    "        # first two sizes are swapped compared to a forward convolution\n",
    "        return (num_input_channels, self.num_filters) + self.filter_size\n",
    "    \n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        #if self.output_size is not None:\n",
    "         #   size = self.output_size\n",
    "        #     if isinstance(self.output_size, T.Variable):\n",
    "        #        size = (None, None)\n",
    "        #    return input_shape[0], self.num_filters, size[0], size[1]\n",
    "\n",
    "        # If self.output_size is not specified, return the smallest shape\n",
    "        # when called from the constructor, self.crop is still called self.pad:\n",
    "        crop = getattr(self, 'crop', getattr(self, 'pad', None))\n",
    "        crop = crop if isinstance(crop, tuple) else (crop,) * self.n\n",
    "        batchsize = input_shape[0]\n",
    "        return ((batchsize, self.num_filters) +\n",
    "                tuple(conv_input_length(input, filter, stride, p)\n",
    "                      for input, filter, stride, p\n",
    "                      in zip(input_shape[2:], self.filter_size,\n",
    "                             self.stride, crop)))\n",
    "\n",
    "    #pad v crop, filter_flip nastavim na not \n",
    "    #def convolve(self, input, **kwargs):\n",
    "    #    border_mode = 'half' if self.crop == 'same' else self.crop\n",
    "    #    conved = self.convolution(input, self.W, self.input_shape, self.get_W_shape(),\n",
    "    #                              subsample=self.stride,\n",
    "    #                              border_mode=border_mode,\n",
    "    #                              filter_flip=not self.flip_filters)\n",
    "    #    return conved\n",
    "    \n",
    "    def convolve(self, input, **kwargs):\n",
    "        border_mode = 'half' if self.crop == 'same' else self.crop\n",
    "        op = T.nnet.abstract_conv.AbstractConv3d_gradInputs(\n",
    "            imshp=self.output_shape,\n",
    "            kshp=self.get_W_shape(),\n",
    "            subsample=self.stride, border_mode=border_mode,\n",
    "            filter_flip=not self.flip_filters)\n",
    "        output_size = self.output_shape[2:]\n",
    "        if isinstance(self.output_size, T.Variable):\n",
    "            output_size = self.output_size\n",
    "        elif any(s is None for s in output_size):\n",
    "            output_size = self.get_output_shape_for(input.shape)[2:]\n",
    "        conved = op(self.W, input, output_size)\n",
    "        return conved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def contracting_block(layer):\n",
    "    #ugotovi num_filters, padding\n",
    "    layer = layers.Conv3DLayer(layer, num_filters=1, filter_size=(2, 2, 2), stride=2, pad=0)\n",
    "    #print(theano.tensor.shape(lasagne.layers.get_output(layer)))\n",
    "    tmp_layer = layer\n",
    "    #ugotovi primeren batch norm layer\n",
    "    layer = layers.BatchNormLayer(layer)\n",
    "    #ugotovi primeren prelu layer\n",
    "    layer = layers.prelu(layer)\n",
    "    #ugotovi num_filters, padding\n",
    "    layer = layers.Conv3DLayer(layer, num_filters=1, filter_size=(3, 3, 3), stride=1, pad=1)\n",
    "    #print(theano.tensor.shape(lasagne.layers.get_output(layer)))\n",
    "    layer = layers.ElemwiseSumLayer([layer, tmp_layer])\n",
    "    layer = layers.batch_norm(layer)\n",
    "    layer = layers.prelu(layer)\n",
    "    return layer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def start(input):\n",
    "    layer = layers.Conv3DLayer(input, num_filters=1, filter_size=(3, 3, 3), stride=1, pad=1)\n",
    "    #print(theano.tensor.shape(lasagne.layers.get_output(layer)))\n",
    "    #print(theano.tensor.shape(lasagne.layers.get_output(layer)))\n",
    "    layer = layers.BatchNormLayer(layer)\n",
    "    layer = layers.prelu(layer)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def expanding_block(layer):\n",
    "    # dodaj feature merging block\n",
    "    layer = layers.Conv3DLayer(layer, num_filters=1, filter_size=(1, 1, 1), stride=1, pad=0)\n",
    "    layer = layers.BatchNormLayer(layer)\n",
    "    layer = layers.prelu(layer)\n",
    "    # kako deluje deconvolutional layer --> DEKONVOLUCIJA\n",
    "    #layer = layers.Conv3DLayer(layer, num_filters=1, filter_size=(1, 1, 1), stride=1, pad=0.5)\n",
    "    layer = Conv3DLayerTransposed(layer, num_filters=1, filter_size=(2, 2, 2), stride=2, crop=0)\n",
    "    layer = layers.BatchNormLayer(layer)\n",
    "    layer = layers.prelu(layer)\n",
    "    layer = layers.Conv3DLayer(layer, num_filters=1, filter_size=(3, 3, 3), stride=1, pad=1)\n",
    "    layer = layers.BatchNormLayer(layer)\n",
    "    layer = layers.prelu(layer)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binary_jaccard_index(predictions,targets):\n",
    "    intersection = theano.tensor.minimum(predictions, targets)\n",
    "    union = theano.tensor.maximum(predictions, targets)\n",
    "    axes = tuple(range(1,5))\n",
    "    return intersection.sum(axis=axes) / union.sum(axis=axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1L, 20L, 150L, 150L)\n",
      "(1L, 20L, 150L, 150L)\n",
      "(1L, 20L, 150L, 150L)\n",
      "(1L, 20L, 150L, 150L)\n",
      "(1L, 20L, 150L, 150L)\n",
      "(1L, 20L, 150L, 150L)\n",
      "(1L, 20L, 150L, 150L)\n",
      "(1L, 20L, 150L, 150L)\n"
     ]
    }
   ],
   "source": [
    "#load the data\n",
    "\n",
    "data = np.load('data-150-150-20.npy')\n",
    "seg_data = np.load('segdata-150-150-20.npy')\n",
    "\n",
    "data = np.expand_dims(data, axis=1)\n",
    "seg_data = np.expand_dims(seg_data, axis=1)\n",
    "\n",
    "train_data = data[:-2]\n",
    "validation_data = data[-2:]\n",
    "train_seg = seg_data[:-2]\n",
    "validation_seg = seg_data[-2:]\n",
    "\n",
    "for x in train_seg:\n",
    "    print(x.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input dimension mis-match. (input[0].shape[3] = 148, input[1].shape[3] = 150)\nApply node that caused the error: Elemwise{sub,no_inplace}(Elemwise{Composite{((i0 * i1 * i2) + (i0 * i3 * i4))}}.0, <TensorType(float64, 5D)>)\nToposort index: 561\nInputs types: [TensorType(float64, (False, True, False, False, False)), TensorType(float64, 5D)]\nInputs shapes: [(8L, 1L, 20L, 148L, 148L), (8L, 1L, 20L, 150L, 150L)]\nInputs strides: [(3504640L, 3504640L, 175232L, 1184L, 8L), (3600000L, 3600000L, 180000L, 1200L, 8L)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[Elemwise{sqr,no_inplace}(Elemwise{sub,no_inplace}.0), Elemwise{Composite{((i0 * i1) / i2)}}[(0, 1)](TensorConstant{(1L, 1L, 1..1L) of 2.0}, Elemwise{sub,no_inplace}.0, Elemwise{mul,no_inplace}.0)]]\n\nBacktrace when the node is created(use Theano flag traceback.limit=N to make it longer):\n  File \"C:\\Anaconda2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Anaconda2\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Anaconda2\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-41-936f9a88602d>\", line 14, in <module>\n    loss = lasagne.objectives.squared_error(prediction, target_var)\n  File \"C:\\Anaconda2\\lib\\site-packages\\lasagne\\objectives.py\", line 198, in squared_error\n    return theano.tensor.square(a - b)\n\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-936f9a88602d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[1;31m#visualize.plot_conv_weights(layer)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[1;31m#print(lasagne.utils.floatX(prediction).shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_seg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[1;31m#print(eval('prediction[2]'))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[1;31m#theano.printing.pprint(prediction[2][2])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\metodjazbec\\AppData\\Roaming\\Python\\Python27\\site-packages\\theano\\compile\\function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    896\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[1;32m    899\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m                 \u001b[1;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\metodjazbec\\AppData\\Roaming\\Python\\Python27\\site-packages\\theano\\gof\\link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[0;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[1;31m# extra long error message in that case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m     \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\metodjazbec\\AppData\\Roaming\\Python\\Python27\\site-packages\\theano\\compile\\function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input dimension mis-match. (input[0].shape[3] = 148, input[1].shape[3] = 150)\nApply node that caused the error: Elemwise{sub,no_inplace}(Elemwise{Composite{((i0 * i1 * i2) + (i0 * i3 * i4))}}.0, <TensorType(float64, 5D)>)\nToposort index: 561\nInputs types: [TensorType(float64, (False, True, False, False, False)), TensorType(float64, 5D)]\nInputs shapes: [(8L, 1L, 20L, 148L, 148L), (8L, 1L, 20L, 150L, 150L)]\nInputs strides: [(3504640L, 3504640L, 175232L, 1184L, 8L), (3600000L, 3600000L, 180000L, 1200L, 8L)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[Elemwise{sqr,no_inplace}(Elemwise{sub,no_inplace}.0), Elemwise{Composite{((i0 * i1) / i2)}}[(0, 1)](TensorConstant{(1L, 1L, 1..1L) of 2.0}, Elemwise{sub,no_inplace}.0, Elemwise{mul,no_inplace}.0)]]\n\nBacktrace when the node is created(use Theano flag traceback.limit=N to make it longer):\n  File \"C:\\Anaconda2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Anaconda2\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Anaconda2\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-41-936f9a88602d>\", line 14, in <module>\n    loss = lasagne.objectives.squared_error(prediction, target_var)\n  File \"C:\\Anaconda2\\lib\\site-packages\\lasagne\\objectives.py\", line 198, in squared_error\n    return theano.tensor.square(a - b)\n\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "input_var = theano.tensor.tensor5()\n",
    "target_var = theano.tensor.tensor5()\n",
    "\n",
    "\n",
    "layer = lasagne.layers.InputLayer((None, 1, 20, 150, 150), input_var)\n",
    "layer = start(layer)\n",
    "layer = contracting_block(layer)\n",
    "layer = contracting_block(layer)\n",
    "layer = expanding_block(layer)\n",
    "layer = expanding_block(layer)\n",
    "\n",
    "prediction = lasagne.layers.get_output(layer)\n",
    "#uporabiti pravi loss metric\n",
    "loss = lasagne.objectives.squared_error(prediction, target_var)\n",
    "loss = loss.mean() + 1e-4 * lasagne.regularization.regularize_network_params(layer, lasagne.regularization.l2)\n",
    "\n",
    "#print(loss.eval())\n",
    "\n",
    "# create parameter update expressions\n",
    "params = lasagne.layers.get_all_params(layer, trainable=True)\n",
    "updates = lasagne.updates.adam(loss, params, learning_rate=0.001)\n",
    "\n",
    "# compile training function that updates parameters and returns training loss\n",
    "train_fn = theano.function([input_var, target_var], loss, updates=updates)\n",
    "\n",
    "# train network (assuming you've got some training data in numpy arrays)\n",
    "for epoch in range(10):\n",
    "    #visualize.plot_conv_weights(layer)\n",
    "    #print(lasagne.utils.floatX(prediction).shape)\n",
    "    loss = train_fn(train_data, train_seg)\n",
    "    #print(eval('prediction[2]'))\n",
    "    #theano.printing.pprint(prediction[2][2]) \n",
    "    print(\"Epoch %d: Loss %g\" % (epoch + 1, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "x = 2\n",
    "print(eval('x'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
